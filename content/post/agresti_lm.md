---
title: "Foundations of Linear and Generalized Linear Models"
date: 2020-02-26T19:39:16-05:00
draft: false
---

When people on r/rstats ask what is a good introduction to statistics I normally
see Casella's "Statistical Inference" recommended. While I did use that book in
my Mathematical Statistics course I believe that Foundations of Linear and
Generalized Linear Models is much better.

---------------

### A Geometric View of Statistics

Agreti choses to teach statistics with the foundations of geometry, specifically
projections. I don't recall any other text that defined the residual as the
projection of the model space onto the data space. I thought this approach was
aesthetic and entertaining. 

### Tough Matrix Calculus

I know linear algebra, I know advanced calculus, but Matrix Calculus is
something I am not so great at. For this reason I had some difficulty following
some of the derivations.

### Code

I think that joining theory with code is fantastic. I love it when books bring
the two together. 

### Exercises

The exercises at the end of the book are some of the best modeling exercises I
have had. I think he does a good job at brining out subtle differences in
modeling techniques. 

### Bayes

I like that he brought in some theory and code that displayed the benefits of
Bayes modeling. I think that this is too polarizing at times. 

### References

I think that his notes and references are well thought out. Good references send
me down a happy rabbit hole and that is exactly what his references did for me.
He had one interesting reference to Likelihoodist h-modeling that I remember
reading about for some time.

